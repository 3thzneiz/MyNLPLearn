{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit https://github.com/greydanus/pythonic_ocr\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from preprocessor import Preprocessor as img_prep\n",
    "\n",
    "class LiteOCR:\n",
    "\tdef __init__(self, fn=\"alpha_weights.pkl\", pool_size=2):\n",
    "\t\t[weights, meta] = pickle.load(open(fn, 'rb'), encoding='latin1') #currently, this class MUST be initialized from a pickle file\n",
    "\t\tself.vocab = meta[\"vocab\"]\n",
    "\n",
    "\t\tself.img_rows = meta[\"img_side\"] ; self.img_cols = meta[\"img_side\"]\n",
    "\n",
    "\t\tself.CNN = LiteCNN()\n",
    "\t\tself.CNN.load_weights(weights)\n",
    "\t\tself.CNN.pool_size=int(pool_size)\n",
    "\n",
    "\tdef predict(self, image):\n",
    "\t\tprint(image.shape)\n",
    "\t\tX = np.reshape(image, (1, 1, self.img_rows, self.img_cols))\n",
    "\t\tX = X.astype(\"float32\")\n",
    "\n",
    "\t\tpredicted_i = self.CNN.predict(X)\n",
    "\t\treturn self.vocab[predicted_i]\n",
    "\n",
    "class LiteCNN:\n",
    "\tdef __init__(self):\n",
    "\t\tself.layers = [] # a place to store the layers\n",
    "\t\tself.pool_size = None # size of pooling area for max pooling\n",
    "\n",
    "\tdef load_weights(self, weights):\n",
    "\t\tassert not self.layers, \"Weights can only be loaded once!\"\n",
    "\t\tfor k in range(len(weights.keys())):\n",
    "\t\t\tself.layers.append(weights['layer_{}'.format(k)])\n",
    "\n",
    "\tdef predict(self, X):\n",
    "\t\tassert not not self.layers, \"Weights must be loaded before making a prediction!\"\n",
    "\t\tprint(X.shape)\n",
    "\t\th = self.cnn_layer(X, layer_i=0, border_mode=\"full\") ; X = h\n",
    "\t\tprint(X.shape)\n",
    "\t\th = self.relu_layer(X) ; X = h\n",
    "\t\th = self.cnn_layer(X, layer_i=2, border_mode=\"valid\") ; X = h\n",
    "\t\th = self.relu_layer(X) ; X = h\n",
    "\t\th = self.maxpooling_layer(X) ; X = h\n",
    "\t\th = self.dropout_layer(X, .25) ; X = h\n",
    "\t\th = self.flatten_layer(X) ; X = h\n",
    "\t\th = self.dense_layer(X, layer_i=7) ; X = h\n",
    "\t\th = self.relu_layer(X) ; X = h\n",
    "\t\th = self.dropout_layer(X, .5) ; X = h\n",
    "\t\th = self.dense_layer(X, layer_i=10) ; X = h\n",
    "\t\th = self.softmax_layer2D(X) ; X = h\n",
    "\t\tmax_i = self.classify(X)\n",
    "\t\treturn max_i[0]\n",
    "\n",
    "\tdef maxpooling_layer(self, convolved_features):\n",
    "\t\tnb_features = convolved_features.shape[0]\n",
    "\t\tnb_images = convolved_features.shape[1]\n",
    "\t\tconv_dim = convolved_features.shape[2]\n",
    "\t\tres_dim = int(conv_dim / self.pool_size)       #assumed square shape\n",
    "\n",
    "\t\tpooled_features = np.zeros((nb_features, nb_images, res_dim, res_dim))\n",
    "\t\tfor image_i in range(nb_images):\n",
    "\t\t\tfor feature_i in range(nb_features):\n",
    "\t\t\t\tfor pool_row in range(res_dim):\n",
    "\t\t\t\t\trow_start = pool_row * self.pool_size\n",
    "\t\t\t\t\trow_end   = row_start + self.pool_size\n",
    "\n",
    "\t\t\t\t\tfor pool_col in range(res_dim):\n",
    "\t\t\t\t\t\tcol_start = pool_col * self.pool_size\n",
    "\t\t\t\t\t\tcol_end   = col_start + self.pool_size\n",
    "\n",
    "\t\t\t\t\t\tpatch = convolved_features[feature_i, image_i, row_start : row_end,col_start : col_end]\n",
    "\t\t\t\t\t\tpooled_features[feature_i, image_i, pool_row, pool_col] = np.max(patch)\n",
    "\t\treturn pooled_features\n",
    "\n",
    "\tdef cnn_layer(self, X, layer_i=0, border_mode = \"full\"):\n",
    "\t\tfeatures = self.layers[layer_i][\"param_0\"]\n",
    "\t\tbias = self.layers[layer_i][\"param_1\"]\n",
    "# \t\tprint('features')\n",
    "# \t\tprint(features)\n",
    "# \t\tprint('bias')\n",
    "# \t\tprint(bias)\n",
    "\t\tpatch_dim = features[0].shape[-1]\n",
    "# \t\tprint('patch_dim')\n",
    "# \t\tprint(patch_dim)\n",
    "\t\tnb_features = features.shape[0]\n",
    "\t\tprint('nb_features')\n",
    "\t\tprint(nb_features)\n",
    "\t\timage_dim = X.shape[2] #assume image square\n",
    "# \t\tprint('image_dim')\n",
    "# \t\tprint(image_dim)\n",
    "\t\timage_channels = X.shape[1]\n",
    "# \t\tprint('image_channels')\n",
    "# \t\tprint(image_channels)\n",
    "\t\tnb_images = X.shape[0]\n",
    "\t\tprint('nb_images')\n",
    "\t\tprint(nb_images)\n",
    "\t\tif border_mode == \"full\":\n",
    "\t\t\tconv_dim = image_dim + patch_dim - 1\n",
    "\t\telif border_mode == \"valid\":\n",
    "\t\t\tconv_dim = image_dim - patch_dim + 1\n",
    "\t\tconvolved_features = np.zeros((nb_images, nb_features, conv_dim, conv_dim));\n",
    "\t\tprint('convolved_features')\n",
    "\t\tprint(convolved_features)\n",
    "\t\tfor image_i in range(nb_images):\n",
    "\t\t\tfor feature_i in range(nb_features):\n",
    "\t\t\t\tconvolved_image = np.zeros((conv_dim, conv_dim))\n",
    "\t\t\t\tfor channel in range(image_channels):\n",
    "\t\t\t\t\tfeature = features[feature_i, channel, :, :]\n",
    "\n",
    "\t\t\t\t\timage   = X[image_i, channel, :, :]\n",
    "\t\t\t\t\tconvolved_image += self.convolve2d(image, feature, border_mode);\n",
    "\n",
    "\t\t\t\tconvolved_image = convolved_image + bias[feature_i]\n",
    "\t\t\t\tconvolved_features[image_i, feature_i, :, :] = convolved_image\n",
    "\t\treturn convolved_features\n",
    "\n",
    "\tdef dense_layer(self, X, layer_i=0):\n",
    "\t\tW = self.layers[layer_i][\"param_0\"]\n",
    "\t\tb = self.layers[layer_i][\"param_1\"]\n",
    "\t\toutput = np.dot(X, W) + b\n",
    "\t\treturn output\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef convolve2d(image, feature, border_mode=\"full\"):\n",
    "\t\timage_dim = np.array(image.shape)\n",
    "\t\tfeature_dim = np.array(feature.shape)\n",
    "\t\ttarget_dim = image_dim + feature_dim - 1\n",
    "\t\tfft_result = np.fft.fft2(image, target_dim) * np.fft.fft2(feature, target_dim)\n",
    "\t\ttarget = np.fft.ifft2(fft_result).real\n",
    "\n",
    "\t\tif border_mode == \"valid\":\n",
    "\t\t\t# To compute a valid shape, either np.all(x_shape >= y_shape) or\n",
    "\t\t\t# np.all(y_shape >= x_shape).\n",
    "\t\t\tvalid_dim = image_dim - feature_dim + 1\n",
    "\t\t\tif np.any(valid_dim < 1):\n",
    "\t\t\t\tvalid_dim = feature_dim - image_dim + 1\n",
    "\t\t\tstart_i = (target_dim - valid_dim) // 2\n",
    "\t\t\tend_i = start_i + valid_dim\n",
    "\t\t\ttarget = target[start_i[0]:end_i[0], start_i[1]:end_i[1]]\n",
    "\t\treturn target\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef shuffle(X, y):\n",
    "\t\tassert X.shape[0] == y.shape[0], \"X and y first dimensions must match\"\n",
    "\t\tp = np.random.permutation(X.shape[0])\n",
    "\t\treturn X[p], y[p]\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef vectorize(y, vocab):\n",
    "\t\tnb_classes = len(vocab)\n",
    "\t\tY = np.zeros((len(y), nb_classes))\n",
    "\t\tfor i in range(len(y)):\n",
    "\t\t\tindex = np.where(np.char.find(vocab, y[i]) > -1)[0][0]\n",
    "\t\t\tY[i, index] = 1.\n",
    "\t\treturn Y\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef trtest_split(X,y,fraction):\n",
    "\t\tboundary=int(X.shape[0]*fraction)\n",
    "\t\treturn (X[:boundary], y[:boundary]), (X[boundary:], y[boundary:])\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef sigmoid(x):\n",
    "\t\treturn 1.0/(1.0+np.exp(-x))\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef hard_sigmoid(x):\n",
    "\t\tslope = 0.2\n",
    "\t\tshift = 0.5\n",
    "\t\tx = (x * slope) + shift\n",
    "\t\tx = np.clip(x, 0, 1)\n",
    "\t\treturn x\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef relu_layer(x):\n",
    "\t\tz = np.zeros_like(x)\n",
    "\t\treturn np.where(x>z,x,z)\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef softmax_layer2D(w):\n",
    "\t\tmaxes = np.amax(w, axis=1)\n",
    "\t\tmaxes = maxes.reshape(maxes.shape[0], 1)\n",
    "\t\te = np.exp(w - maxes)\n",
    "\t\tdist = e / np.sum(e, axis=1, keepdims=True)\n",
    "\t\treturn dist\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef repeat_vector(X, n):\n",
    "\t\ty = np.ones((X.shape[0], n, X.shape[2])) * X\n",
    "\t\treturn y\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef dropout_layer(X, p):\n",
    "\t\tretain_prob = 1. - p\n",
    "\t\tX *= retain_prob\n",
    "\t\treturn X\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef classify(X):\n",
    "\t\treturn X.argmax(axis=-1)\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef flatten_layer(X):\n",
    "\t\tflatX = np.zeros((X.shape[0],np.prod(X.shape[1:])))\n",
    "\t\tfor i in range(X.shape[0]):\n",
    "\t\t\tflatX[i,:] = X[i].flatten(order='C')\n",
    "\t\treturn flatX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = img_prep(fn=\"dataset.txt\")\n",
    "ocr = LiteOCR(fn=\"alpha_weights.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = pp.preprocess('data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wAARCADIAMgDASIAAhEBAxEB/8QAGQABAQEBAQEAAAAAAAAAAAAAAAQDAQIH/8QAIhABAAEDBQADAQEAAAAAAAAAAAECBDMDETJxgRIiQVEx/8QAGgEBAAMBAQEAAAAAAAAAAAAAAAIDBQYBBP/EACQRAQABAgYCAgMAAAAAAAAAAAABAgUDETEyNIEEsRJhEyFR/9oADAMBAAIRAxEAPwD5+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADsRMztEby9iJmcoHBpOjXEb7M068KvD/VcTDyJiQBW9AAAAAAAAAAAAAAAAAAAAG9tEfaf1gotuNXbQtkRPk05/fpCva2S68RGrO36qTXGXxrXeI/BE/aGHqyAcyuAAAAAAAAAAAAAAAAAAAAFFtxq7TqLbjV20bZyY79IV7Wya4y+KU1xl8a124/cIYerIBzC4AAAAAAAAAAAAAAAAAAAAUW3GrtOotuNXbRtnJjv0hXtbJrjL4pTXGXxrXbj9whh6sgHMLgAAAAAAAAAAAAAAAAAAABRbcau06i241dtG2cmO/SFe1smuMvilNcZfGtduP3CGHqyAcwuAAAAAAAAAAAAAAAAAAAAFFtxq7TqLbjV20bZyY79IV7Wya4y+KU1xl8a124/cIYerIBzC4AAAAAAAAAAAAAAAAAAAAUW3GrtOotuNXbRtnJjv0hXtbJrjL4pTXGXxrXbj9whh6sgHMLgAAAAAAAAAAAAAAAAAAABRbcau06rQpiNOJ/rTtVE1eRn/IlCvRomuMvilNcZfGpduP3CGHqyAcwuAAAAAAAAAAAAAAAAAAAAG2jq/H61f5/WIuwMevAr+dDyYzjJbNdMRvNUJNSr51zLyPp8vz6/JiKZjKHlNOQA+BIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB//2Q==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,)\n",
      "(1, 1, 20, 20)\n",
      "nb_features\n",
      "32\n",
      "nb_images\n",
      "1\n",
      "convolved_features\n",
      "[[[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   ..., \n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   ..., \n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   ..., \n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   ..., \n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   ..., \n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   ..., \n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]]]]\n",
      "(1, 32, 22, 22)\n",
      "nb_features\n",
      "32\n",
      "nb_images\n",
      "1\n",
      "convolved_features\n",
      "[[[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   ..., \n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   ..., \n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   ..., \n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   ..., \n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   ..., \n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   ..., \n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...,  0.  0.  0.]]]]\n"
     ]
    }
   ],
   "source": [
    "char_prediction= ocr.predict(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
