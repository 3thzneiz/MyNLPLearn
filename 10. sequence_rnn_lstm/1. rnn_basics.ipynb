{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rnn_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_cell_forward(xt, a_prev, parameters):\n",
    "    \"\"\"\n",
    "    Implements a single forward step of the RNN-cell as described in Figure (2)\n",
    "\n",
    "    Arguments:\n",
    "    xt -- your input data at timestep \"t\", numpy array of shape (n_x, m).\n",
    "    a_prev -- Hidden state at timestep \"t-1\", numpy array of shape (n_a, m)\n",
    "    parameters -- python dictionary containing:\n",
    "                        Wax -- Weight matrix multiplying the input, numpy array of shape (n_a, n_x)\n",
    "                        Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a)\n",
    "                        Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)\n",
    "                        ba --  Bias, numpy array of shape (n_a, 1)\n",
    "                        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)\n",
    "    Returns:\n",
    "    a_next -- next hidden state, of shape (n_a, m)\n",
    "    yt_pred -- prediction at timestep \"t\", numpy array of shape (n_y, m)\n",
    "    cache -- tuple of values needed for the backward pass, contains (a_next, a_prev, xt, parameters)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve parameters from \"parameters\"\n",
    "    Wax = parameters[\"Wax\"]\n",
    "    Waa = parameters[\"Waa\"]\n",
    "    Wya = parameters[\"Wya\"]\n",
    "    ba = parameters[\"ba\"]\n",
    "    by = parameters[\"by\"]\n",
    "    \n",
    "    ### START CODE HERE ### (â‰ˆ2 lines)\n",
    "    # compute next activation state using the formula given above\n",
    "    a_next = np.tanh((np.dot(Waa,a_prev)+ np.dot(Wax, xt)+ba))\n",
    "    # compute output of the current cell using the formula given above\n",
    "    yt_pred = softmax(np.dot(Wya, a_next) + by)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # store values you need for backward propagation in cache\n",
    "    cache = (a_next, a_prev, xt, parameters)\n",
    "    \n",
    "    return a_next, yt_pred, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "xt_tmp = np.random.randn(3,10)\n",
    "a_prev_tmp = np.random.randn(5,10)\n",
    "parameters_tmp = {}\n",
    "parameters_tmp['Waa'] = np.random.randn(5,5)\n",
    "parameters_tmp['Wax'] = np.random.randn(5,3)\n",
    "parameters_tmp['Wya'] = np.random.randn(2,5)\n",
    "parameters_tmp['ba'] = np.random.randn(5,1)\n",
    "parameters_tmp['by'] = np.random.randn(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_prev\n",
      "[[-0.69166075 -0.39675353 -0.6871727  -0.84520564 -0.67124613 -0.0126646\n",
      "  -1.11731035  0.2344157   1.65980218  0.74204416]\n",
      " [-0.19183555 -0.88762896 -0.74715829  1.6924546   0.05080775 -0.63699565\n",
      "   0.19091548  2.10025514  0.12015895  0.61720311]\n",
      " [ 0.30017032 -0.35224985 -1.1425182  -0.34934272 -0.20889423  0.58662319\n",
      "   0.83898341  0.93110208  0.28558733  0.88514116]\n",
      " [-0.75439794  1.25286816  0.51292982 -0.29809284  0.48851815 -0.07557171\n",
      "   1.13162939  1.51981682  2.18557541 -1.39649634]\n",
      " [-1.44411381 -0.50446586  0.16003707  0.87616892  0.31563495 -2.02220122\n",
      "  -0.30620401  0.82797464  0.23009474  0.76201118]]\n",
      "(5, 10)\n",
      "=============\n",
      "xt\n",
      "[[ 1.62434536 -0.61175641 -0.52817175 -1.07296862  0.86540763 -2.3015387\n",
      "   1.74481176 -0.7612069   0.3190391  -0.24937038]\n",
      " [ 1.46210794 -2.06014071 -0.3224172  -0.38405435  1.13376944 -1.09989127\n",
      "  -0.17242821 -0.87785842  0.04221375  0.58281521]\n",
      " [-1.10061918  1.14472371  0.90159072  0.50249434  0.90085595 -0.68372786\n",
      "  -0.12289023 -0.93576943 -0.26788808  0.53035547]]\n",
      "(3, 10)\n"
     ]
    }
   ],
   "source": [
    "print('a_prev')\n",
    "print(a_prev_tmp)\n",
    "print(a_prev_tmp.shape)\n",
    "print('=============')\n",
    "print('xt')\n",
    "print(xt_tmp)\n",
    "print(xt_tmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.95442347, -0.97959841, -0.77682357, -0.85960496,  0.2996283 ,\n",
       "        -0.72828789,  0.70341981,  0.396781  ,  0.64215271, -0.68720152],\n",
       "       [-0.77817006, -0.96939535, -0.90158668, -0.89269334, -0.94794605,\n",
       "        -0.62569074, -0.7847199 ,  0.73807292,  0.40638533, -0.49874722],\n",
       "       [ 0.34337788, -0.99997631, -0.99692205, -0.98133709, -0.93123291,\n",
       "        -0.99802557, -0.99662894, -0.93641136, -0.25153222,  0.54770565],\n",
       "       [-0.85404662,  0.97190276,  0.60516394,  0.65999969, -0.68038654,\n",
       "         0.09222782,  0.34729991,  0.41705046, -0.44431726,  0.74395075],\n",
       "       [ 0.59584544,  0.18141802,  0.61311866,  0.99808218,  0.85016201,\n",
       "         0.99980978, -0.18887155,  0.99815551,  0.6531151 ,  0.82872037]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tanh(np.dot(parameters_tmp['Waa'],a_prev_tmp )+ np.dot(parameters_tmp['Wax'], xt_tmp)+parameters_tmp['ba'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_next[4] = \n",
      " [ 0.59584544  0.18141802  0.61311866  0.99808218  0.85016201  0.99980978\n",
      " -0.18887155  0.99815551  0.6531151   0.82872037]\n",
      "a_next.shape = \n",
      " (5, 10)\n",
      "yt_pred[1] =\n",
      " [0.9888161  0.01682021 0.21140899 0.36817467 0.98988387 0.88945212\n",
      " 0.36920224 0.9966312  0.9982559  0.17746526]\n",
      "yt_pred.shape = \n",
      " (2, 10)\n"
     ]
    }
   ],
   "source": [
    "a_next_tmp, yt_pred_tmp, cache_tmp = rnn_cell_forward(xt_tmp, a_prev_tmp, parameters_tmp)\n",
    "print(\"a_next[4] = \\n\", a_next_tmp[4])\n",
    "print(\"a_next.shape = \\n\", a_next_tmp.shape)\n",
    "print(\"yt_pred[1] =\\n\", yt_pred_tmp[1])\n",
    "print(\"yt_pred.shape = \\n\", yt_pred_tmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_next_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
